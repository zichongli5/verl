# DAPO trainer config with QAT (Quantization-Aware Training) support
# This config extends dapo_trainer.yaml with QAT-specific settings
#
# QAT Modes:
#   - w4a16: Weight-only 4-bit quantization (NVFP4)
#   - w4a4:  Weight + Activation 4-bit quantization (NVFP4)
#
# Usage:
#   python -m verl.trainer.main_ppo \
#     --config-path recipe/qat/config \
#     --config-name dapo_qat_trainer \
#     actor_rollout_ref.actor.qat.mode=w4a16 \
#     actor_rollout_ref.actor.qat.quantization_config_path=recipe/qat/config/nvfp4_w4a16.json

hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  gen_batch_size: ${data.train_batch_size}

reward_model:
  reward_manager: dapo
  overlong_buffer: 
    enable: False
    len: 0
    penalty_factor: 0.0
    log: False

algorithm:
  filter_groups:
    _target_: verl.trainer.config.FilterGroupsConfig
    enable: False
    metric: null
    max_num_gen_batches: 0

trainer:
  project_name: verl-dapo-qat

# ============================================================
# QAT Configuration (overrides defaults in dp_actor.yaml)
# ============================================================
actor_rollout_ref:
  actor:
    qat:
      # Enable QAT
      enable: true
      # Quantization mode: "w4a16" (weight-only) or "w4a4" (weight + activation)
      mode: "w4a16"
      # Quantization group size (NVFP4 requires 16)
      group_size: 16
      # Layers to skip (not quantized)
      ignore_patterns:
        - "lm_head"
        - "embed_tokens"
        - "re:.*mlp.gate$"
      # Activation observer for W4A4: "static_minmax", "memoryless_minmax", "minmax"
      activation_observer: "static_minmax"
      # vLLM quantization config JSON path (relative to project root)
      # W4A16: recipe/qat/config/nvfp4_w4a16.json
      # W4A4:  recipe/qat/config/nvfp4_w4a4.json
      quantization_config_path: null  # Specify in run script
